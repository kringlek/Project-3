{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "412d8b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from turtle import pd\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d291b454",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28mprint\u001b[39m(gif_df)\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# browser.quit()\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# return gif_list\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[43mscrape_gifs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mscrape_gifs\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Scrape page into Soup\u001b[39;00m\n\u001b[1;32m     12\u001b[0m html \u001b[38;5;241m=\u001b[39m browser\u001b[38;5;241m.\u001b[39mhtml\n\u001b[0;32m---> 13\u001b[0m soup \u001b[38;5;241m=\u001b[39m \u001b[43mbs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhtml\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhtml.parser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m href_array \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m link \u001b[38;5;129;01min\u001b[39;00m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, attrs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m'\u001b[39m: re\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^tropics\u001b[39m\u001b[38;5;124m\"\u001b[39m)}):\n",
      "File \u001b[0;32m~/.conda/envs/PythonData/lib/python3.9/site-packages/bs4/__init__.py:313\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(markup, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m'\u001b[39m):        \u001b[38;5;66;03m# It's a file-type object.\u001b[39;00m\n\u001b[1;32m    312\u001b[0m     markup \u001b[38;5;241m=\u001b[39m markup\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m--> 313\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmarkup\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    314\u001b[0m         (\u001b[38;5;28misinstance\u001b[39m(markup, \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m markup)\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(markup, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m markup)\n\u001b[1;32m    316\u001b[0m ):\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;66;03m# Issue warnings for a couple beginner problems\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;66;03m# involving passing non-markup to Beautiful Soup.\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;66;03m# Beautiful Soup will still parse the input as markup,\u001b[39;00m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;66;03m# since that is sometimes the intended behavior.\u001b[39;00m\n\u001b[1;32m    321\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_markup_is_url(markup):\n\u001b[1;32m    322\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_markup_resembles_filename(markup)                \n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "def scrape_gifs():      \n",
    "        # Set up Splinter\n",
    "    executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "    browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "    url = \"https://bmcnoldy.rsmas.miami.edu/tropics/radar/\"\n",
    "    browser.visit(url)\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Scrape page into Soup\n",
    "    html = browser.html\n",
    "    soup = bs(html, \"html.parser\")\n",
    "\n",
    "    href_array = []\n",
    "    for link in soup.find_all('a', attrs={'href': re.compile(\"^tropics\")}):\n",
    "        href_array.append(link.get('href'))\n",
    "        # if WHATEVER does not end in '.gif' drop from array\n",
    "\n",
    "        # print(href_array)\n",
    "        # return href_array\n",
    "\n",
    "        df = pd.DataFrame(href_array, columns=['gif_url']) \n",
    "\n",
    "        gif_df = df[df['gif_url'].str.endswith('.gif')]\n",
    "\n",
    "        print(gif_df)\n",
    "\n",
    "    # browser.quit()\n",
    "    # return gif_list\n",
    "scrape_gifs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bce7b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Areas affected</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Year</th>\n",
       "      <th>Wind Speed (mph)</th>\n",
       "      <th>Pressure (hPa)</th>\n",
       "      <th>Damages ($)</th>\n",
       "      <th>Deaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>San Felipe</td>\n",
       "      <td>Lesser Antilles, The Bahamas,United States Eas...</td>\n",
       "      <td>September</td>\n",
       "      <td>13</td>\n",
       "      <td>1928</td>\n",
       "      <td>160</td>\n",
       "      <td>929</td>\n",
       "      <td>100000000.0</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Camaguey</td>\n",
       "      <td>Lesser Antilles, Jamaica, Cayman Islands, Cuba...</td>\n",
       "      <td>November</td>\n",
       "      <td>5</td>\n",
       "      <td>1932</td>\n",
       "      <td>175</td>\n",
       "      <td>915</td>\n",
       "      <td>40000000.0</td>\n",
       "      <td>3103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New England</td>\n",
       "      <td>Eastern United States, Southwestern Quebec</td>\n",
       "      <td>September</td>\n",
       "      <td>19</td>\n",
       "      <td>1938</td>\n",
       "      <td>160</td>\n",
       "      <td>940</td>\n",
       "      <td>306000000.0</td>\n",
       "      <td>682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Janet</td>\n",
       "      <td>Lesser Antilles, Central America</td>\n",
       "      <td>September</td>\n",
       "      <td>27</td>\n",
       "      <td>1955</td>\n",
       "      <td>175</td>\n",
       "      <td>914</td>\n",
       "      <td>65800000.0</td>\n",
       "      <td>1023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Inez</td>\n",
       "      <td>Greater Antilles, Florida, Mexico</td>\n",
       "      <td>September</td>\n",
       "      <td>28</td>\n",
       "      <td>1966</td>\n",
       "      <td>165</td>\n",
       "      <td>927</td>\n",
       "      <td>229000000.0</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Name                                     Areas affected      Month  \\\n",
       "0   San Felipe  Lesser Antilles, The Bahamas,United States Eas...  September   \n",
       "1     Camaguey  Lesser Antilles, Jamaica, Cayman Islands, Cuba...   November   \n",
       "2  New England         Eastern United States, Southwestern Quebec  September   \n",
       "3        Janet                   Lesser Antilles, Central America  September   \n",
       "4         Inez                  Greater Antilles, Florida, Mexico  September   \n",
       "\n",
       "   Day  Year  Wind Speed (mph) Pressure (hPa)  Damages ($)  Deaths  \n",
       "0   13  1928               160            929  100000000.0    4000  \n",
       "1    5  1932               175            915   40000000.0    3103  \n",
       "2   19  1938               160            940  306000000.0     682  \n",
       "3   27  1955               175            914   65800000.0    1023  \n",
       "4   28  1966               165            927  229000000.0     756  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    #Read in Data from CSV\n",
    "    \n",
    "    hurricane_csv = \"Data/hurricane_clean_dataset.csv\"\n",
    "    hurricane_data = pd.read_csv(hurricane_csv)\n",
    "    hurricane_data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
